{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ee2566",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "Demonstrating the Attachments Library Architecture\n",
    "\n",
    "This script walks through the internal architectural stages of the `attachments` library \n",
    "to provide a clearer understanding of how it processes files. We'll show how an input path\n",
    "goes through Input Handling, Detection, Parsing, (Contact Sheet Generation), and finally \n",
    "to Rendering/Output Preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e77800",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 0. Setup\n",
    "\n",
    "First, let's import necessary modules and set up some dummy files for our demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import shutil # For cleaning up the temp directory\n",
    "from attachments import Attachments # Assuming it's installed and importable\n",
    "from attachments.detectors import Detector # To demonstrate detector separately\n",
    "from attachments.parsers import ParserRegistry, TextParser # To show registry and fallback parser\n",
    "\n",
    "# Create a temporary directory for our sample files\n",
    "temp_dir_path = tempfile.mkdtemp()\n",
    "print(f\"Temporary directory created: {temp_dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdca6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample file 1: A simple text file\n",
    "text_content = \"This is a simple text file for demonstration.\"\n",
    "text_file_path = os.path.join(temp_dir_path, \"sample.txt\")\n",
    "with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text_content)\n",
    "print(f\"Created: {text_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample file 2: A file with an unknown extension to test fallback\n",
    "unknown_ext_content = \"This content is in a file with an unknown extension.\"\n",
    "unknown_file_path = os.path.join(temp_dir_path, \"sample.unknownext\")\n",
    "with open(unknown_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(unknown_ext_content)\n",
    "print(f\"Created: {unknown_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b4358",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Sample file 3: A local image path (replace with a real small image path if possible for full demo)\n",
    "# For CI/portability, we'll create a tiny dummy PNG here. \n",
    "# In a real scenario, you'd use an actual image path like \"path/to/your/image.png\"\n",
    "from PIL import Image\n",
    "dummy_image_path = os.path.join(temp_dir_path, \"dummy_image.png\")\n",
    "try:\n",
    "    img = Image.new('RGB', (60, 30), color = 'red')\n",
    "    img.save(dummy_image_path, 'PNG')\n",
    "    print(f\"Created dummy image: {dummy_image_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not create dummy image (Pillow/PIL needed): {e}\")\n",
    "    dummy_image_path = None # Fallback if Pillow is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d56ad3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Sample URL (publicly accessible small image or document)\n",
    "# Using a very small, reliable PNG for demonstration\n",
    "sample_url = \"https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_42x16dp.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524d5b0",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 1. Input Handling & Preprocessing\n",
    "\n",
    "This initial stage is crucial. The library needs a concrete local file to operate on and must parse any operational directives from the input strings.\n",
    "\n",
    "*   **URL Downloading**: If a path is a URL, it's downloaded to a temporary local file.\n",
    "*   **Path String Parsing**: Directives (e.g., `[resize:100x100]`) are separated from the main file path.\n",
    "\n",
    "Let's initialize `Attachments` with a mix of our inputs:\n",
    "- The sample URL.\n",
    "- The local dummy image with an operation string.\n",
    "- The simple text file.\n",
    "- The file with an unknown extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f81aa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "paths_for_attachments = []\n",
    "paths_for_attachments.append(sample_url) # The URL\n",
    "if dummy_image_path:\n",
    "    paths_for_attachments.append(f\"{dummy_image_path}[rotate:180,resize:300x300]\") # Local image with ops\n",
    "paths_for_attachments.append(text_file_path) # Simple text file\n",
    "paths_for_attachments.append(unknown_file_path) # Unknown extension file\n",
    "\n",
    "for path in paths_for_attachments:\n",
    "    print(f\"Input path: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a14ac8",
   "metadata": {
    "lines_to_next_cell": 0,
    "region_name": "md"
   },
   "source": [
    "Initialize Attachments - this will trigger the whole pipeline internally.\n",
    "Using verbose=True to see potential warnings or processing steps if any are printed by the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2bffb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "atts_instance = Attachments(*paths_for_attachments, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6723f1d",
   "metadata": {
    "lines_to_next_cell": 0,
    "region_name": "md"
   },
   "source": [
    "The Attachments object stores the original paths it was given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "atts_instance.original_paths_with_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c90566",
   "metadata": {
    "lines_to_next_cell": 0,
    "region_name": "md"
   },
   "source": [
    "Let's manually demonstrate what _parse_path_string does for an input with operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb8f71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "atts_instance._parse_path_string(f\"{dummy_image_path}[format:jpeg,quality:70]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36150091",
   "metadata": {
    "lines_to_next_cell": 0,
    "region_name": "md"
   },
   "source": [
    "For the URL, a download to a temporary file happens internally within _process_paths.\n",
    "We can't easily show the temp path here without modifying the library or deep inspection,\n",
    "but we can see its original URL was recorded in the final attachment data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62c284",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 2. Detection\n",
    "After preprocessing, the `Detector` attempts to identify the file type. This is crucial for selecting the correct parser.\n",
    "We will inspect the `type` and `original_detected_type` fields in the `attachments_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Inspecting Detected Types from attachments_data ---\")\n",
    "if not atts_instance.attachments_data:\n",
    "    print(\"No attachments were processed successfully, skipping Detection demonstration details.\")\n",
    "else:\n",
    "    for item in atts_instance.attachments_data:\n",
    "        item_id = item.get('id', 'N/A')\n",
    "        original_path = item.get('original_path_str', 'N/A')\n",
    "        final_type = item.get('type', 'N/A')\n",
    "        original_detection = item.get('original_detected_type', 'Not specifically recorded or same as final type')\n",
    "        \n",
    "        print(f\"\\nAttachment ID: {item_id} (from: {original_path})\")\n",
    "        print(f\"  - Final type used for parsing: '{final_type}'\")\n",
    "        if final_type == 'txt' and original_detection != 'Not specifically recorded or same as final type' and original_detection != 'txt':\n",
    "            print(f\"  - Originally detected as: '{original_detection}' (then fell back to 'txt')\")\n",
    "        elif final_type == 'txt' and original_path.endswith('.unknownext'):\n",
    "             print(f\"  - Likely fell back to 'txt' due to unknown extension or no specific parser.\")\n",
    "        elif final_type == 'png' and original_path == sample_url: # Example for Google logo\n",
    "            print(f\"  - Detected type for URL '{sample_url}' is '{final_type}'.\")\n",
    "        elif final_type == 'jpeg' and original_path.startswith(dummy_image_path if dummy_image_path else \"\"): # For our dummy image\n",
    "            print(f\"  - Detected type for local image '{dummy_image_path}' is initially png, then ops change output to '{final_type}'. Type field shows '{item.get('type')}' from parser output.\")\n",
    "            # Note: The 'type' here is what the ImageParser determines based on content/ops, might not be the raw *detected* type before parsing if ops change format.\n",
    "            # The `original_format` field inside image attachment data is more indicative of initial detection for images.\n",
    "            if 'original_format' in item:\n",
    "                print(f\"    Original image format (from Pillow): {item['original_format']}\")\n",
    "\n",
    "# Demonstrate Detector class separately for clarity\n",
    "print(\"\\n--- Demonstrating Detector class directly ---\")\n",
    "detector = Detector()\n",
    "dummy_txt_type = detector.detect(text_file_path)\n",
    "print(f\"Detector.detect('{text_file_path}'): '{dummy_txt_type}'\") # Expected: txt\n",
    "\n",
    "if dummy_image_path:\n",
    "    dummy_img_type = detector.detect(dummy_image_path)\n",
    "    print(f\"Detector.detect('{dummy_image_path}'): '{dummy_img_type}'\") # Expected: png\n",
    "\n",
    "unkn_type = detector.detect(unknown_file_path)\n",
    "print(f\"Detector.detect('{unknown_file_path}'): '{unkn_type}'\") # Expected: None or fallback to txt depending on detector's internal logic if it tries basic sniffing\n",
    "\n",
    "# For a URL, detector might get a hint from Content-Type if it were passed directly, \n",
    "# but Attachments class handles URL download and then detects the local temp file.\n",
    "\n",
    "print(\"\\n--- Stage 2 Demonstration Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9987ee",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 3. Parsing\n",
    "\n",
    "Based on the detected type, the `ParserRegistry` provides the correct parser. Each parser extracts data (text, image objects, audio segments, metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Inspecting Parsed Content from attachments_data ---\")\n",
    "if not atts_instance.attachments_data:\n",
    "    print(\"No attachments were processed, skipping Parsing demonstration details.\")\n",
    "else:\n",
    "    for item in atts_instance.attachments_data:\n",
    "        print(f\"\\nParsed data for: {item.get('id', item.get('original_path_str', 'N/A'))} (Type: {item.get('type')})\")\n",
    "        if \"text\" in item and item['text']:\n",
    "            # Displaying only a snippet of text if it's long\n",
    "            text_snippet = item['text'][:100].replace(\"\\n\", \" \") + (\"...\" if len(item['text']) > 100 else \"\")\n",
    "            print(f\"  Text (snippet): '{text_snippet}'\")\n",
    "        if \"image_object\" in item:\n",
    "            img_obj = item['image_object']\n",
    "            print(f\"  Image Object: Present (Type: {type(img_obj)}, Mode: {getattr(img_obj, 'mode', 'N/A')}, Size: {getattr(img_obj, 'size', 'N/A')})\")\n",
    "            if \"operations_applied\" in item and item[\"operations_applied\"]:\n",
    "                print(f\"  Image Operations Applied: {item['operations_applied']}\")\n",
    "            if \"output_format\" in item:\n",
    "                print(f\"  Image Output Format: {item['output_format']}\")\n",
    "        if item.get('type') == 'txt' and item.get('original_path_str') == unknown_file_path:\n",
    "            print(f\"  Content of '{unknown_file_path}': '{item.get('text')}'\")\n",
    "\n",
    "print(\"\\n--- Stage 3 Demonstration Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce465d",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 4. Contact Sheet Generation (Conceptual)\n",
    "\n",
    "For document types like PDF, PPTX, DOCX, a contact sheet (visual preview image) is generated and added as another attachment item.\n",
    "We are not using such a document in this basic script, but if we did, an image item corresponding to its contact sheet would appear in `atts_instance.attachments_data`.\n",
    "Example: If `doc.pdf` was an input, you might find an item with `type='jpeg'` and `id='contact_sheet_doc1'` (or similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0a377",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Stage 4: Contact Sheet Generation (Conceptual) ---\")\n",
    "print(\"No document types like PDF/PPTX were used in this script to demonstrate contact sheet generation directly.\")\n",
    "print(\"If they were, an additional image item for the contact sheet would be in atts_instance.attachments_data.\")\n",
    "\n",
    "print(\"\\n--- Stage 4 Demonstration Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235540cb",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 5. Rendering & Output Preparation\n",
    "\n",
    "Finally, the processed data can be rendered in various formats for LLM consumption or display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85623e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Demonstrating Output Methods ---\")\n",
    "if not atts_instance.attachments_data:\n",
    "    print(\"No attachments processed, skipping most output demonstrations.\")\n",
    "else:\n",
    "    # String representation (default XML)\n",
    "    print(\"\\n1. `str(atts_instance)` (XML Output Snippet):\")\n",
    "    xml_output = str(atts_instance)\n",
    "    print(xml_output[:300] + \"...\") # Show a snippet\n",
    "\n",
    "    # Base64 encoded images\n",
    "    print(\"\\n2. `atts_instance.images` (Snippets of Base64 Data URIs):\")\n",
    "    if atts_instance.images:\n",
    "        for i, img_data_uri in enumerate(atts_instance.images):\n",
    "            print(f\"  Image {i+1} (snippet): {img_data_uri[:70]}...\")\n",
    "    else:\n",
    "        print(\"  No images available in atts_instance.images\")\n",
    "\n",
    "    # LLM-specific content formatting\n",
    "    print(\"\\n3. `atts_instance.to_openai_content('Test prompt for OpenAI')`:\")\n",
    "    openai_content = atts_instance.to_openai_content(\"Test prompt for OpenAI\")\n",
    "    print(openai_content)\n",
    "\n",
    "    # Claude content can also be generated (similar structure)\n",
    "    # print(\"\\n`atts_instance.to_claude_content('Test prompt for Claude')`:\")\n",
    "    # claude_content = atts_instance.to_claude_content(\"Test prompt for Claude\")\n",
    "    # print(claude_content)\n",
    "\n",
    "    # Markdown representation for Jupyter/IPython\n",
    "    print(\"\\n4. `atts_instance._repr_markdown_()` (String Output):\")\n",
    "    markdown_repr = atts_instance._repr_markdown_()\n",
    "    print(markdown_repr) # This will be rendered nicely in a Jupyter notebook\n",
    "\n",
    "print(\"\\n--- Stage 5 Demonstration Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fc8de",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Remove the temporary directory and its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(temp_dir_path)\n",
    "    print(f\"\\nSuccessfully removed temporary directory: {temp_dir_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError removing temporary directory {temp_dir_path}: {e}\")\n",
    "\n",
    "print(\"\\n--- Architecture Demonstration Script Finished ---\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "region_name,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
