---
description: 
globs: 
alwaysApply: false
---
# Development Rules & Patterns

## Python Execution in Cursor + uv

**CRITICAL**: When using Cursor with uv virtual environments:

- ‚úÖ **ALWAYS use**: `uv run python -c "..."`
- ‚ùå **NEVER use**: `python -c "..."` (points to Cursor AppImage!)

The bare `python` command in Cursor points to the AppImage instead of the virtual environment Python, causing import and module issues.

## Type Annotation Rules

**NO `typing.Any`!**
- ‚ùå **NEVER use**: `typing.Any` - breaks `isinstance()` in decorators
- ‚úÖ **USE instead**: `object` for generic fallbacks, specific types otherwise
- üîß **Reason**: Our decorator system uses `isinstance()` which fails with `typing.Any`

```python
# Bad - causes TypeError in isinstance()
@presenter
def text(data: Any) -> str:
    return str(data)

# Good - works with isinstance() 
@presenter
def text(data: object) -> str:
    return str(data)
```

## Testing Patterns

```bash
# Good - uses venv Python
uv run python -c "from src.attachments.core import load"
uv run pytest tests/

# Bad - uses AppImage Python
python -c "from src.attachments.core import load"  # FAILS
```

## Documentation Workflow

```bash
# Convert Python scripts to Jupyter notebooks
uv run python scripts/convert_to_notebooks.py

# Build MyST documentation with executable notebooks  
uv run myst build

# Serve docs locally for preview
uv run myst start

# Documentation structure:
# docs/scripts/*.py ‚Üí docs/examples/*.ipynb ‚Üí _build/html/
```

## Licensing Architecture 

**MIT License Compatibility**: 

- ‚úÖ **Default**: `pypdf` (BSD) + `pypdfium2` (BSD/Apache) 
- ‚ö†Ô∏è **Optional**: `PyMuPDF/fitz` (AGPL) - requires explicit opt-in

Users get MIT-compatible PDF support by default, can opt into AGPL for more features if they accept the licensing implications.

## Bayesian Beliefs & Updates

### PDF Library Strategy
- **Prior**: PyMuPDF is best (feature-rich) 
- **Evidence**: AGPL licensing conflicts with MIT goals
- **Updated**: pypdf + pypdfium2 provides good MIT-compatible alternative
- **Confidence**: 85% - covers 90% of use cases with permissive licensing

### Modular Architecture
- **Prior**: Monolithic approach easier to develop
- **Evidence**: Type dispatch + decorators create clean separation  
- **Updated**: Modular approach worth complexity for extensibility
- **Confidence**: 90% - enables easy addition of new components

### Testing Strategy  
- **Prior**: Manual testing sufficient during development
- **Evidence**: Linter errors and import issues caught only by tests
- **Updated**: `uv run pytest` essential before claiming completion
- **Confidence**: 95% - prevents integration issues

### Documentation Workflow
- **Prior**: Separate docs and code examples hard to maintain
- **Evidence**: Jupytext + MyST allows executable Python scripts as docs
- **Updated**: Python scripts in `docs/scripts/` ‚Üí auto-convert to notebooks in `docs/examples/`
- **Confidence**: 90% - streamlines tutorial development and maintenance

### Type Annotations
- **Prior**: `typing.Any` is harmless for generic fallbacks
- **Evidence**: `typing.Any` breaks `isinstance()` in decorator dispatch system
- **Updated**: Use `object` for generic types, specific types otherwise
- **Confidence**: 95% - `typing.Any` causes runtime errors with `isinstance()`

## Scientific Method Checklist

For each change:
1. **State assumptions** - what do we expect to happen?
2. **Make predictions** - what should we observe if correct?  
3. **Test & verify** - run `uv run pytest` to confirm
4. **Update beliefs** - document what we learned

# Cursor Rules for Attachments Library

## Core Principles

The [README.md](mdc:README.md) is the ground truth on the interface we aim to implement.

We aim for a clean and robust architectural design outline, adhering closely to your goals of modularity, extensibility, ease of use, and flexibility in rendering.

Refactor as soon as you see a need to it to make the code easier for you to work with!

use uv and .venv (my uv virtual environment).

use:
uv run pytest

run the unit tests before claiming your changes are done!

always use the scientific method: 1) state your assumptions, 2) make testable predictions and 3) check them to confirm the code and system is in the state you believe and it works as you believe.Allocate bayesian believes and update them maybe even store them in your own .mdc rule file?!

## OpenAI API Format Distinction

**CRITICAL**: There are TWO different OpenAI API formats that must NOT be mixed:

### 1. Chat Completions API (Standard)
```python
client.chat.completions.create(
    model="gpt-4",
    messages=[
        {
            "role": "user", 
            "content": [
                {"type": "text", "text": "What's in this image?"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://example.com/image.jpg"}
                }
            ]
        }
    ]
)
```

### 2. Responses API (Different Format)
```python
input_data = ctx.to_openai_responses("what is in this image?")
client.responses.create(
    model="gpt-4",
    input=input_data  # Direct list usage
)

# Returns:
[
    {
        "role": "user",
        "content": [
            {"type": "input_text", "text": "what is in this image?"},
            {
                "type": "input_image", 
                "image_url": "https://example.com/image.jpg"
            }
        ]
    }
]
```

### Key Differences:
- **Chat Completions**: `messages=result` + `"type": "text"` + `"image_url": {"url": "..."}`
- **Responses**: `input=result` + `"type": "input_text"` + `"image_url": "..."`  (direct string)
- **Both return**: `List[Dict]` but with different content structure

### Adapter Implementation:
- `openai_chat` ‚Üí Chat Completions API format
- `openai_responses` ‚Üí Responses API format  
- These must NEVER be mixed or call each other

## Accessing User's Jupyter Kernel Context

**CRITICAL**: When the user is working in VSCode Jupyter and you need to see their current kernel state, In/Out history, or debug issues, use the **Kernel Inspector** script:

### Quick Start
```bash
# Basic inspection (most common use case)
uv run python docs/scripts/kernel_inspector.py

# Get help and see all options
uv run python docs/scripts/kernel_inspector.py --help
```

### Common Debugging Scenarios

**üîç Debug specific variables:**
```bash
# Inspect the 'agent' object
uv run python docs/scripts/kernel_inspector.py --var agent

# Check what's in 'response'
uv run python docs/scripts/kernel_inspector.py --var response
```

**‚ùå Find errors quickly:**
```bash
# Look for recent errors/exceptions
uv run python docs/scripts/kernel_inspector.py --errors-only
```

**üß™ Test code in their kernel:**
```bash
# Execute custom code to understand their environment
uv run python docs/scripts/kernel_inspector.py --exec "print(type(agent))"
uv run python docs/scripts/kernel_inspector.py --exec "list(agent.__dict__.keys())"
```

**üìú See more context:**
```bash
# Show last 10 inputs/outputs instead of 4
uv run python docs/scripts/kernel_inspector.py --history 10
```

### What You Get
- **In[N] history**: Code cells the user executed
- **Out[N] history**: Results and outputs
- **Current variables**: All objects with their types
- **Error detection**: Recent exceptions and failures
- **Custom execution**: Run code in their environment

### Pro Workflow
1. **Start basic**: `uv run python docs/scripts/kernel_inspector.py`
2. **Focus on issues**: Use `--var` for specific objects or `--errors-only` for problems
3. **Test hypotheses**: Use `--exec` to run quick tests
4. **Get more context**: Use `--history 10` if you need more background

See `docs/scripts/KERNEL_INSPECTOR_GUIDE.md` for complete usage guide.

This approach gives you complete visibility into the user's Jupyter session without manual copy/paste.
